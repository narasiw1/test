{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipyparallel\n",
    "from tempfile import TemporaryFile\n",
    "data = TemporaryFile()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clients = ipyparallel.Client('/home/snara025/.ipython/profile_myprofile/security/ipcontroller-client.json')#, url_file='/home/snara025/.ipython/profile_myprofile/security/ipcontroller-client.json', sshserver='192.168.233.126',\n",
    "clients.ids\n",
    "\n",
    "lview = clients.load_balanced_view() \n",
    "dview = clients[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from builtins import str\n",
    "from builtins import range\n",
    "from os.path import join as opj\n",
    "\n",
    "from nipype.interfaces.dcm2nii import Dcm2niix # to convert Dicom to Niftii\n",
    "\n",
    "\n",
    "import os                                    # system functions\n",
    "import sys\n",
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "import nipype.interfaces.fsl as fsl          # fsl\n",
    "import nipype.interfaces.afni as afni\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "import nipype.algorithms.modelgen as model   # model generation\n",
    "import nipype.algorithms.rapidart as ra      # artifact detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "# define important package paths here\n",
    "os.system('module load fsl/5.0.10')\n",
    "os.system('module load afni')\n",
    "sys.path.append(\"/home/applications/dcm2niix/build/bin\")\n",
    "sys.path.append(\"/home/applications/fsl/5.0.10/bin\")\n",
    "sys.path.append(\"/home/applications/fsl/5.0.10/etc\")\n",
    "sys.path.append('/home/applications/afni/abin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make directories\n",
    "* use the following code to create directories based on whatever format you want (e.g. BIDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "subject_list = ['sub-01','sub-02', 'sub-03', 'sub-04']\n",
    "\n",
    "for subs in subject_list:\n",
    "    os.mkdir('/scratch/sanjay/GRT/fmri_data/nifti')\n",
    "    os.mkdir('/scratch/sanjay/GRT/fmri_data/nifti/{}'.format(subs))\n",
    "    os.mkdir('/scratch/sanjay/GRT/fmri_data/nifti/{}/anat'.format(subs))\n",
    "    os.mkdir('/scratch/sanjay/GRT/fmri_data/nifti/{}/func'.format(subs))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dicom Convert\n",
    "\n",
    "* Needs to be done only once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "sys.path.append(\"/home/applications/dcm2niix/build/bin\")\n",
    "\n",
    "\n",
    "\n",
    "for a in range(1,5,1): # in reality this should be from 1 to 4 but I'm skipping 1 cuz it's already done\n",
    "    convertnode = pe.Node(Dcm2niix(), name ='convert_dicoms', iter_field=['source_dir'])\n",
    "    convertnode.inputs.source_dir = '/scratch/sanjay/GRT/fmri_data/sessions/session-0{}/' .format(a)\n",
    "\n",
    "    convertnode.inputs.output_dir = '/scratch/sanjay/GRT/fmri_data/nifti/session-0{}/' .format(a)\n",
    "    #convertnode.inputs.merge_images = True\n",
    "\n",
    "    convertnode.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inputs\n",
    "\n",
    "### This is a super important section. It is where we specify the input structure for nipype. \n",
    "\n",
    "* going off http://nipype.readthedocs.io/en/latest/users/grabbing_and_sinking.html http://nipype.readthedocs.io/en/latest/users/examples/fmri_fsl.html\n",
    "\n",
    "* not sure which T1 to use, we have like 2 for each session\n",
    "* The purpose of MapNode is to map the node when the node takes only one input. Some regular nodes take more than 1 input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/scratch/sanjay/GRT/fmri_data/nifti/' #  ' '/Users/Narasiwodeyar'\n",
    "output_dir = '/scratch/sanjay/GRT/fmri_data/testing/output/'\n",
    "working_dir ='/scratch/sanjay/GRT/fmri_data/testing/output/working' #   '/Users/Narasiwodeyar/Google Drive/Experiments/GRT-fMRI/scripts/'\n",
    "\n",
    "# list of subject identifiers\n",
    "subject_list = ['sub-02', 'sub-01']\n",
    "\n",
    "task_list = ['train_', 'test_']\n",
    "run_list = ['1','2','3','4','5','6','7','8','9','10','11','12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#info = dict(func=[['subject_id', ['run01' ]]], struct=[['subject_id', 't1']])\n",
    "\n",
    "infosource = pe.Node(interface=util.IdentityInterface(fields=['subject_id','task_id','run_id']),name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list),('task_id',task_list ),('run_id',run_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Rename Files\n",
    "\n",
    "* This works perfectly. What we need is to merge the two sessions from each subject into 1, and reorganize into bids format.\n",
    "\n",
    "* Note that the following code needs to be changed based on how you want your data. \n",
    "* I am gonna call the runs in second session as test_7,train_7, test_8, train_8 etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for i in range(1,7,1):\n",
    "\n",
    "    os.system('mv /scratch/sanjay/GRT/fmri_data/nifti/session-03/*VISUAL_Train_{}.nii  /scratch/sanjay/GRT/fmri_data/nifti/sub-01/func/sub-01_train_{}.nii' .format(i,i)) \n",
    "    os.system('mv /scratch/sanjay/GRT/fmri_data/nifti/session-03/*VISUAL_{}.nii /scratch/sanjay/GRT/fmri_data/nifti/sub-01/func/sub-01_test_{}.nii' .format(i,i) )\n",
    "    \n",
    "    os.system('mv /scratch/sanjay/GRT/fmri_data/nifti/session-02/*VISUAL_Train_{}.nii  /scratch/sanjay/GRT/fmri_data/nifti/sub-02/func/sub-02_train_{}.nii'.format(i,(i+6))) \n",
    "    os.system('mv /scratch/sanjay/GRT/fmri_data/nifti/session-02/*VISUAL_{}.nii /scratch/sanjay/GRT/fmri_data/nifti/sub-02/func/sub-02_test_{}.nii' .format(i,(i+6)))\n",
    "    \n",
    "    os.system('mv /scratch/sanjay/GRT/fmri_data/nifti/session-04/*VISUAL_Train_{}.nii  /scratch/sanjay/GRT/fmri_data/nifti/sub-01/func/sub-01_train_{}.nii' .format(i,(i+6))) \n",
    "    os.system('mv /scratch/sanjay/GRT/fmri_data/nifti/session-04/*VISUAL_{}.nii  /scratch/sanjay/GRT/fmri_data/nifti/sub-01/func/sub-01_test_{}.nii' .format(i,(i+6)) )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data\n",
    "* read this about Data grabbing http://nipype.readthedocs.io/en/latest/users/grabbing_and_sinking.html\n",
    "* and this http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.io.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Something super important is that the nifti files MUST be uncompressed for this step: nii NOT nii.gz\n",
    "\n",
    "func_file = opj('{subject_id}', 'func',\n",
    "                '{subject_id}_{task_id}{run_id}.nii')\n",
    "\n",
    "anat_file = opj('{subject_id}','anat', '{subject_id}_T1.nii')# we might have to make 3rd iterable for the runs\n",
    "#resampled_t1 = opj('{subject_id}','anat', '{subject_id}_T1_resampled.nii')\n",
    "brain = opj('{subject_id}','anat', '{subject_id}_brain.nii')\n",
    "\n",
    "\n",
    "templates = {'func': func_file, 'anat': anat_file,  't1_brain':brain }\n",
    "datasource = pe.Node(nio.SelectFiles(templates),name='Get_files')\n",
    "datasource.inputs.base_directory = data_dir\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsl.FSLCommand.set_default_output_type('NIFTI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preproc = pe.Workflow(name='preproc', base_dir=working_dir) # this creates a pre-processing workflow of sorts. pe is pipleline engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## do slicetiming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slice_timer = pe.MapNode(interface=fsl.SliceTimer(interleaved = True), name= 'Slice_time_correction', iterfield=['in_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Use FSL McFLIRT to do motion correction\n",
    "\n",
    "* see http://nipype.readthedocs.io/en/latest/interfaces/generated/interfaces.fsl/preprocess.html#mcflirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "motion_correct = pe.MapNode(interface=fsl.MCFLIRT(save_mats=True,\n",
    "                                                  save_plots=True, interpolation = 'sinc', output_type='NIFTI', dof =6),\n",
    "                            name='Realign_with_MCFLIRT',\n",
    "                            iterfield=['in_file'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot and save motion corrected plots\n",
    "\n",
    "plot_motion = pe.MapNode(interface=fsl.PlotMotionParams(in_source='fsl'),\n",
    "                         name='Check_motion_plots',\n",
    "                         iterfield=['in_file'])\n",
    "plot_motion.iterables = ('plot_type', ['rotations', 'translations'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Strip skull\n",
    "\n",
    "* You need a skull stripped T1 to do registration.\n",
    "* I used the skull stripped T1 from recon-all ouput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#strip = pe.MapNode(interface = fsl.BET(output_type='NIFTI', functional=False), name='Strip_skull_T1', iterfield=['in_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### co-registration to structural needs T1 to be in same space\n",
    "\n",
    "* This has been achieved using AFNI's 3d-resample. \n",
    "* I did this in the command line because I had trouble getting afni to work properly in the parallel engines\n",
    "* Besides this only needs to be done once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#resample = pe.Node(interface = afni.Resample(outputtype= 'NIFTI', voxel_size=(2.4,2.4,2.4)), name= 'Resample_T1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the average volume as input for FLIRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_vol = pe.MapNode(interface=fsl.MeanImage(output_type='NIFTI',dimension= 'T'),name='Select_avg_vol' ,iterfield = ['in_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### register 4d functional run using epi_reg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reg = pe.MapNode(interface =fsl.EpiReg(output_type = 'NIFTI'), name= 'Register_4d_funcs', iterfield = ['epi', 't1_brain', 't1_head'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg = pe.MapNode(interface =fsl.FLIRT(output_type = 'NIFTI', cost_func='bbr', dof = 6), name= 'FLIRT_reg', iterfield = ['in_file', 'reference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the inverse transform matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverse = pe.MapNode(interface = fsl.ConvertXFM(invert_xfm=True),name= 'Get_inverse_transform', iterfield=['in_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Apply transform to functionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = pe.MapNode(interface = fsl.ApplyXFM(interp='trilinear', output_type = 'NIFTI'), name = 'Transform_func_runs', iterfield = ['in_file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all runs from one subject into 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge = pe.Node(interface = fsl.Merge(dimension = 't'), name= 'Merge_all_runs_per_subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data storing node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasink = pe.Node(nio.DataSink(), name='store_outputs')\n",
    "datasink.inputs.base_directory = output_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## workflow connections \n",
    "\n",
    "* Define all workflow connections here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "preproc.connect(datasource, 'func', slice_timer, 'in_file')\n",
    "preproc.connect(slice_timer, 'slice_time_corrected_file', motion_correct, 'in_file')\n",
    "\n",
    "preproc.connect(infosource,'subject_id',datasource, 'subject_id')\n",
    "preproc.connect(infosource,'task_id',datasource, 'task_id')\n",
    "preproc.connect(infosource,'run_id',datasource, 'run_id')\n",
    "preproc.connect(motion_correct, 'out_file', datasink, 'motion.corrected_files')\n",
    "preproc.connect(motion_correct, 'par_file', plot_motion, 'in_file')\n",
    "preproc.connect(motion_correct, 'par_file', datasink,'motion.par')\n",
    "preproc.connect(plot_motion, 'out_file', datasink, 'plots')\n",
    "\n",
    "preproc.connect(motion_correct, 'out_file', avg_vol, 'in_file')\n",
    "preproc.connect(avg_vol, 'out_file', reg, 'in_file') # input functional files to registrations step\n",
    "preproc.connect(datasource, 't1_brain', reg, 'reference') # store registered files\n",
    "\n",
    "preproc.connect(reg, 'out_matrix_file', inverse, 'in_file')\n",
    "preproc.connect(inverse, 'out_file', transform, 'in_matrix_file' )\n",
    "preproc.connect(motion_correct, 'out_file', transform, 'in_file')\n",
    "preproc.connect(datasource, 'anat', transform, 'reference')\n",
    "preproc.connect(transform, 'out_file', datasink, 'final')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualing workflow\n",
    "* Use the following cell to generate a visual workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#preproc.write_graph(\"workflow_graph_mcf.dot\", graph2use = 'colored')\n",
    "#from IPython.display import Image\n",
    "#Image(filename=\"workflow_graph_mcf.dot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preproc.run(plugin='IPython', plugin_args={ 'url_file': '/home/snara025/.ipython/profile_myprofile/security/ipcontroller-client.json'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "par = np.loadtxt('/scratch/sanjay/GRT/fmri_data/testing/output/datasink/motion/par/sub-02/sub-02_train_1_mcf.nii.gz.par1_bold_mcf.par')\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 5))\n",
    "axes[0].set_ylabel('rotation (radians)')\n",
    "axes[0].plot(par[0:, :3])\n",
    "axes[1].plot(par[0:, 3:])\n",
    "axes[1].set_xlabel('time (TR)')\n",
    "axes[1].set_ylabel('translation (mm)')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
